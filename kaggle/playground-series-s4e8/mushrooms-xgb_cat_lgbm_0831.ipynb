{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd70bf5",
   "metadata": {
    "papermill": {
     "duration": 0.01075,
     "end_time": "2024-08-16T07:24:35.983041",
     "exception": false,
     "start_time": "2024-08-16T07:24:35.972291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#d8ecff; color: #009dff;margin:0; display:inline-block;padding:.4rem;border-radius:.25rem;border:1px solid #009dff\">Importing Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eee77a2",
   "metadata": {
    "papermill": {
     "duration": 2.705462,
     "end_time": "2024-08-16T07:24:38.698336",
     "exception": false,
     "start_time": "2024-08-16T07:24:35.992874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import torch\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.stats import mode\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, auc, classification_report, \n",
    "    confusion_matrix, accuracy_score, matthews_corrcoef, f1_score,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, StratifiedShuffleSplit,\n",
    "    StratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
    ")\n",
    "import warnings\n",
    "\n",
    "# Custom metric function\n",
    "def custom_mcc_metric(y_true, y_pred):\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    return mcc\n",
    "\n",
    "custom_mcc_scorer = make_scorer(name='mcc',\n",
    "                                score_func=custom_mcc_metric,\n",
    "                                greater_is_better=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ef89b",
   "metadata": {
    "papermill": {
     "duration": 0.009945,
     "end_time": "2024-08-16T07:24:38.718437",
     "exception": false,
     "start_time": "2024-08-16T07:24:38.708492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "  ### <p style=\"background-color: #fdefff;color:#c12eff;display: inline-block;padding:.6rem;border-radius:.5rem;border: 1px solid #c059ff\">Loading data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a10a225-88a2-4b75-9840-5df12c5eb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b00cf1",
   "metadata": {
    "papermill": {
     "duration": 15.322649,
     "end_time": "2024-08-16T07:24:54.050532",
     "exception": false,
     "start_time": "2024-08-16T07:24:38.727883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data : (3116945, 22)\n",
      "test_data : (2077964, 21)\n",
      "sample_submission_data : (2077964, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd(), \"kaggle/playground-series-s4e8/train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd(), \"kaggle/playground-series-s4e8/test.csv\"))\n",
    "sample_submission_data = pd.read_csv(os.path.join(os.getcwd(), \"kaggle/playground-series-s4e8/sample_submission.csv\"))\n",
    "\n",
    "print(\"train_data :\", train_data.shape)\n",
    "print(\"test_data :\", test_data.shape)\n",
    "print(\"sample_submission_data :\", sample_submission_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbb4ff3-b93e-4125-a589-52c5343fd895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training XGBClassifier\n",
      "================================================================================\n",
      "--- Fold 1 MCC Score: 0.984589\n",
      "--- Fold 2 MCC Score: 0.984413\n",
      "--- Fold 3 MCC Score: 0.984830\n",
      "--- Fold 4 MCC Score: 0.984426\n",
      "--- Fold 5 MCC Score: 0.984419\n",
      "\n",
      "---> Mean MCC Score: 0.984535 ± 0.000161\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Training CatBoostClassifier\n",
      "================================================================================\n",
      "--- Fold 1 MCC Score: 0.984549\n",
      "--- Fold 2 MCC Score: 0.984270\n",
      "--- Fold 3 MCC Score: 0.984758\n",
      "--- Fold 4 MCC Score: 0.984263\n",
      "--- Fold 5 MCC Score: 0.984131\n",
      "\n",
      "---> Mean MCC Score: 0.984394 ± 0.000228\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Training LGBMClassifier\n",
      "================================================================================\n",
      "--- Fold 1 MCC Score: 0.984666\n",
      "--- Fold 2 MCC Score: 0.984513\n",
      "--- Fold 3 MCC Score: 0.984869\n",
      "--- Fold 4 MCC Score: 0.984497\n",
      "--- Fold 5 MCC Score: 0.984395\n",
      "\n",
      "---> Mean MCC Score: 0.984588 ± 0.000165\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/playground-series-s4e8/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m oof_probs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     97\u001b[0m     oof_preds[model] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39mmean(oof_probs[model], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m sub \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/playground-series-s4e8/sample_submission.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m preds \u001b[38;5;241m=\u001b[39m [pred \u001b[38;5;28;01mfor\u001b[39;00m model, pred \u001b[38;5;129;01min\u001b[39;00m oof_preds\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    101\u001b[0m md \u001b[38;5;241m=\u001b[39m mode(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(preds)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m preds[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/playground-series-s4e8/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "target = 'class'\n",
    "features = train_data.drop(target, axis=1).columns.to_list()\n",
    "\n",
    "categorical_features = train_data[features].select_dtypes(include='object').columns.to_list()\n",
    "\n",
    "def cleaner(df):\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        df.loc[df[col].value_counts(dropna=False)[df[col]].values < 100, col] = \"noise\"\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "    \n",
    "train_data = cleaner(train_data)\n",
    "test_data = cleaner(test_data)\n",
    "\n",
    "cap_diameter_mean = pd.concat([train_data['cap-diameter'], test_data['cap-diameter']]).mean(numeric_only=True)\n",
    "train_data['cap-diameter'].fillna(cap_diameter_mean, inplace=True)\n",
    "test_data['cap-diameter'].fillna(cap_diameter_mean, inplace=True)\n",
    "\n",
    "X = train_data.copy()\n",
    "y = X.pop(target)\n",
    "\n",
    "lab_enc = LabelEncoder().fit(y)\n",
    "y = lab_enc.transform(y)\n",
    "\n",
    "def model_trainer(model, X, y, n_splits=5, random_state=42):\n",
    "    skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    oof_probs, oof_mccs = [], []\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training {model.__class__.__name__}\")\n",
    "    print(\"=\"*80, end=\"\\n\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "        X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx, :], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mcc = matthews_corrcoef(y_pred, y_test)\n",
    "        oof_mccs.append(mcc)\n",
    "        oof_probs.append(model.predict_proba(test_data))\n",
    "        print(f\"--- Fold {fold+1} MCC Score: {mcc:.6f}\")\n",
    "    print(f\"\\n---> Mean MCC Score: {np.mean(oof_mccs):.6f} \\xb1 {np.std(oof_mccs):.6f}\\n\\n\")\n",
    "    return oof_probs, oof_mccs\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 2407,\n",
    "    'eta': 0.009462133032592785,\n",
    "    'gamma': 0.2865859948765318,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 47,\n",
    "    'subsample': 0.6956431754146083,\n",
    "    'colsample_bytree': 0.3670732604094118,\n",
    "    'grow_policy': 'lossguide',\n",
    "    'max_leaves': 73,\n",
    "    'enable_categorical': True,\n",
    "    'n_jobs': -1,\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist'\n",
    "} # 0.9844272567086021\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1041,\n",
    "    'learning_rate': 0.08777255350163136,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.1259643500248322,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'random_strength': 4.276181166674371e-08,\n",
    "    'bagging_temperature': 0.35995482350907326,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 39,\n",
    "    \"verbose\": False,\n",
    "    \"allow_writing_files\": False,\n",
    "    \"task_type\": 'GPU',\n",
    "    \"cat_features\": categorical_features\n",
    "} # 0.9841773055825763\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': 2500,\n",
    "    'random_state':42,\n",
    "    'max_bin':1024,\n",
    "    'colsample_bytree':0.6,\n",
    "    'reg_lambda': 80,\n",
    "#     'device': 'gpu',\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "oof_probs = {}\n",
    "oof_probs['xgb'], _ = model_trainer(XGBClassifier(**xgb_params), X, y, random_state=101)\n",
    "oof_probs['cat'], _ = model_trainer(CatBoostClassifier(**cat_params), X, y, random_state=101)\n",
    "oof_probs['lgb'], _ = model_trainer(LGBMClassifier(**lgb_params), X, y, random_state=101)\n",
    "\n",
    "oof_preds = {}\n",
    "for model in oof_probs.keys():\n",
    "    oof_preds[model] = np.argmax(np.mean(oof_probs[model], axis=0), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04a6965-94d7-483f-a46c-41440d96d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./kaggle/playground-series-s4e8/sample_submission.csv\")\n",
    "preds = [pred for model, pred in oof_preds.items()]\n",
    "md = mode(preds, axis=0)[0] if len(preds)>1 else preds[0]\n",
    "sub[target] = lab_enc.inverse_transform(md)\n",
    "sub.to_csv(\"submission111.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa22a9",
   "metadata": {
    "papermill": {
     "duration": 0.032892,
     "end_time": "2024-08-16T07:27:09.193886",
     "exception": false,
     "start_time": "2024-08-16T07:27:09.160994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#d8ecff; color: #009dff;margin:0; display:inline-block;padding:.4rem;border-radius:.25rem;border:1px solid #009dff\">Handling NaN Values And Less Frequent Categories</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438927a-00d6-4345-8eaa-ee51df6ea6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['id', 'class', 'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color',\n",
    "#        'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
    "#        'stem-height', 'stem-width', 'stem-root', 'stem-surface', 'stem-color',\n",
    "#        'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color',\n",
    "#        'habitat', 'season', 'veil-info'],\n",
    "#       dtype='object')\n",
    "\n",
    "# 결측치와 특성 존재 여부를 동시에 다룰 수 있음: 앞에서 0과 1로 veil-type의 존재 여부를 표현하고, 뒤에서 'unknown'을 통해 veil-color의 결측치를 처리함으로써 두 정보를 효과적으로 결합할 수 있습니다.\n",
    "# 모델 학습에 유용한 정보 제공: 결측치나 특성의 존재 여부를 단순히 무시하지 않고, 이들을 결합하여 모델이 더 많은 패턴을 학습할 수 있게 도와줍니다.\n",
    "# Index(['w', 'y', 'n', 'u', 'k', 'e', 'g', 'p', 'r', 'o', 's', 'a', 't', 'd',\n",
    "#        'i', 'h', 'c', 'f', 'l', 'b', 'z', '8.25', '2.49', '3.32'],\n",
    "#       dtype='object', name='veil-color')\n",
    "# Index(['u', 'w', 'a', 'f', 'e', 'b', 'c', 'y', 'k', 'g', 'n', 's', 'r', 'd',\n",
    "#        'p', 'h', 'i', 'l', 'is None', 't', '21.11', '5.94'],\n",
    "#       dtype='object', name='veil-type')\n",
    "\n",
    "# Index(['f10', 'tnone', 't1', 't7', 't10', 't4', 't2', 't5', 't3', 't9',\n",
    "#        'fnone', 'f1', 'f2', 'f7', 'f4', 't8', 'f5', 'r2', 't6', 'f3', 'l4',\n",
    "#        't0', 'p5', 'z7', 'c10', 'x10', 'f9', 'f6', 's10', 'm9', 'hnone', 's1',\n",
    "#        'g3', 'g5', 'h7', 'e1', 'f0', 'r4', 'dnone', 's5', 'cnone', 'h1', 'p1',\n",
    "#        'h5', 'h10', 'w3', 'y2', 'a10', 'ynone', 'e10', 'p7', '10.310', 's2',\n",
    "#        'o2', 'g10', 'h2', 'g1', 's3', 'p3', 'knone', 'inone', 'nnone', 'rnone',\n",
    "#        'l5', 'c1', 'n10', 'c3', 'o10', 'e4', 'd10', 'f has-ring10', 'lnone',\n",
    "#        'c7', 'e3', 'y1', 'k10'],\n",
    "#       dtype='object', name='has-ring-type')\n",
    "\n",
    "train_data['veil-info'] = train_data['veil-type'].notna().astype(int).astype(str) + train_data['veil-color'].fillna('unknown')\n",
    "cap_shape_mapping = {'b': 0, 'c': 1, 'x': 2, 'f': 3, 's': 4, 'p': 5, 'o': 6}\n",
    "cap_color_mapping = {'n': 0, 'b': 1, 'g': 2, 'r': 3, 'p': 4, 'u': 5, 'e': 6, 'w': 7, 'y': 8, 'l': 9, 'o': 10, 'k': 11}\n",
    "ring_type_mapping = {'c': 0, 'e': 1, 'r': 2, 'g': 3, 'l': 4, 'p': 5, 's': 6, 'z': 7, 'y': 8, 'm': 9, 'f': 10}\n",
    "train_data['cap-shape'] = train_data['cap-shape'].map(cap_shape_mapping).astype(str).str.replace('.0', '', regex=False)\n",
    "train_data['cap-color'] = train_data['cap-color'].map(cap_color_mapping).astype(str).str.replace('.0', '', regex=False)\n",
    "train_data['has-ring-type'] = (\n",
    "    train_data['has-ring'] + \n",
    "    train_data['ring-type'].fillna('none').map(ring_type_mapping).apply(lambda x: f\"{x:.0f}\" if pd.notna(x) else 'none').str.replace('.0', '', regex=False)\n",
    ")\n",
    "\n",
    "test_data['veil-info'] = test_data['veil-type'].notna().astype(int).astype(str) + test_data['veil-color'].fillna('unknown')\n",
    "test_data['cap-shape'] = test_data['cap-shape'].map(cap_shape_mapping).astype(str).str.replace('.0', '', regex=False)\n",
    "test_data['cap-color'] = test_data['cap-color'].map(cap_color_mapping).astype(str).str.replace('.0', '', regex=False)\n",
    "test_data['has-ring-type'] = (\n",
    "    test_data['has-ring'] + \n",
    "    test_data['ring-type'].fillna('none').map(ring_type_mapping).apply(lambda x: f\"{x:.0f}\" if pd.notna(x) else 'none').str.replace('.0', '', regex=False)\n",
    ")\n",
    "\n",
    "train_data = train_data.drop(['id', 'veil-color', 'veil-type', 'has-ring', 'ring-type'], axis=1)\n",
    "test_data = test_data.drop(['id', 'veil-color', 'veil-type', 'has-ring', 'ring-type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca3de9",
   "metadata": {
    "papermill": {
     "duration": 12.420604,
     "end_time": "2024-08-16T07:27:41.801476",
     "exception": false,
     "start_time": "2024-08-16T07:27:29.380872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_feats = ['cap-shape', 'cap-surface', 'cap-color',\n",
    "       'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
    "       'stem-root', 'stem-surface', 'stem-color', 'spore-print-color',\n",
    "       'habitat', 'season', 'veil-info', 'has-ring-type']\n",
    "\n",
    "for feat in cat_feats:\n",
    "    train_data[feat] = train_data[feat].astype('category')\n",
    "for feat in cat_feats:\n",
    "    test_data[feat] = test_data[feat].astype('category')\n",
    "\n",
    "def cleaning(df):\n",
    "    threshold = 100\n",
    "    for feat in cat_feats:\n",
    "        if df[feat].dtype.name == 'category':\n",
    "            # Add 'missing' and 'noise' to categories if not present\n",
    "            if 'missing' not in df[feat].cat.categories:\n",
    "                df[feat] = df[feat].cat.add_categories('missing')\n",
    "            if 'noise' not in df[feat].cat.categories:\n",
    "                df[feat] = df[feat].cat.add_categories('noise')\n",
    "        else:\n",
    "            # Convert to category and add new categories\n",
    "            df[feat] = df[feat].astype('category')\n",
    "            df[feat] = df[feat].cat.add_categories(['missing', 'noise'])\n",
    "        \n",
    "        # Fill missing values with 'missing'\n",
    "        df[feat] = df[feat].fillna('missing')\n",
    "        \n",
    "        # Replace infrequent categories with 'noise'\n",
    "        counts = df[feat].value_counts(dropna=False)\n",
    "        infrequent_categories = counts[counts < threshold].index\n",
    "        df[feat] = df[feat].apply(lambda x: 'missing' if x in infrequent_categories else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#\n",
    "train_data = cleaning(train_data)\n",
    "test_data = cleaning(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82a197",
   "metadata": {
    "papermill": {
     "duration": 83.210705,
     "end_time": "2024-08-16T07:29:05.042161",
     "exception": false,
     "start_time": "2024-08-16T07:27:41.831456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate group means for the train data\n",
    "group_by_features = ['stem-width', 'stem-height']\n",
    "group_means_train = train_data.groupby(group_by_features)['cap-diameter'].mean()\n",
    "\n",
    "def fill_na_with_group_mean(row, group_means):\n",
    "    if pd.isna(row['cap-diameter']):\n",
    "        group = tuple(row[group_by_features])\n",
    "        return group_means.get(group, np.nan)\n",
    "    else:\n",
    "        return row['cap-diameter']\n",
    "\n",
    "train_data['cap-diameter'] = train_data.apply(fill_na_with_group_mean, axis=1, group_means=group_means_train)\n",
    "test_data['cap-diameter'] = test_data.apply(fill_na_with_group_mean, axis=1, group_means=group_means_train)\n",
    "\n",
    "# Calculate the mode from the training data\n",
    "cap_diameter_mode = train_data['cap-diameter'].mode()[0]\n",
    "stem_height_mode = train_data['stem-height'].mode()[0]\n",
    "\n",
    "# Fill missing values in the training data\n",
    "train_data['cap-diameter'] = train_data['cap-diameter'].fillna(cap_diameter_mode)\n",
    "test_data['cap-diameter'] = test_data['cap-diameter'].fillna(cap_diameter_mode)\n",
    "\n",
    "train_data['stem-height'] = train_data['stem-height'].fillna(stem_height_mode)\n",
    "test_data['stem-height'] = test_data['stem-height'].fillna(stem_height_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48739aae",
   "metadata": {
    "papermill": {
     "duration": 0.030299,
     "end_time": "2024-08-16T07:29:18.447641",
     "exception": false,
     "start_time": "2024-08-16T07:29:18.417342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#d8ecff; color: #009dff;margin:0; display:inline-block;padding:.4rem;border-radius:.25rem;border:1px solid #009dff\">Splitting Data</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fb6dd",
   "metadata": {
    "papermill": {
     "duration": 0.064995,
     "end_time": "2024-08-16T07:29:18.542408",
     "exception": false,
     "start_time": "2024-08-16T07:29:18.477413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(['class'], axis=1)\n",
    "y = train_data['class']\n",
    "print(X.shape, y.shape)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866734cf",
   "metadata": {
    "papermill": {
     "duration": 0.00934,
     "end_time": "2024-08-16T07:24:54.069511",
     "exception": false,
     "start_time": "2024-08-16T07:24:54.060171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61208e37-db84-4cde-8afb-e06068db3eea",
   "metadata": {},
   "source": [
    "## Using XGBoost with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6b006-f459-40ba-b591-8b607ed87eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to print the MCC score for each trial\n",
    "def print_mcc_callback(study, trial):\n",
    "    mcc = trial.user_attrs[\"mcc\"]\n",
    "    print(f\"Trial {trial.number}: MCC = {mcc}\")\n",
    "    \n",
    "def model_report(estimator, X, y, cv=5):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"    Model: {estimator.__class__.__name__}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=1/cv, shuffle=True, stratify=y, random_state=42)\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    print(f\"F1 Score : {f1.mean():.6f}\")\n",
    "    print(f\"MCC Score: {mcc.mean():.6f}\")\n",
    "    \n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "xgb_clf = XGBClassifier(enable_categorical=True, device=\"cuda\", tree_method=\"hist\")\n",
    "cat_clf = CatBoostClassifier(\n",
    "    cat_features=cat_feats,\n",
    "    verbose=False,\n",
    "    allow_writing_files=False,\n",
    "    task_type=\"GPU\"\n",
    ")\n",
    "lgb_clf = LGBMClassifier(device='cpu', verbosity=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d61b2-3605-4801-9132-745651718bb0",
   "metadata": {},
   "source": [
    "## 기본값으로 모델링 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80117f-d8c4-46ff-bc2e-87c9b754bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_report(xgb_clf, X, y)\n",
    "model_report(cat_clf, X, y)\n",
    "model_report(lgb_clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953ed56-cdcc-4664-8693-0a78d6b13e9b",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cdf84",
   "metadata": {
    "papermill": {
     "duration": 0.038297,
     "end_time": "2024-08-16T07:29:19.468247",
     "exception": false,
     "start_time": "2024-08-16T07:29:19.429950",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4885)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1200), #  100, 1000\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 22), #5, 10\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0), # 0.5, 1.0\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n",
    "        'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 1.0, 10.0),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-3, 1e-2),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 40, 100),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 40, 100), # 16, 84\n",
    "        'device': 'cuda',\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', enable_categorical=True, early_stopping_rounds=20)\n",
    "    # Fit the model with early stopping\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],  # Validation set\n",
    "        verbose=False                 # Suppress output\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    trial.set_user_attr(\"mcc\", mcc)\n",
    "    return mcc\n",
    "\n",
    "\n",
    "\n",
    "storage = \"sqlite:///xgb.db\"\n",
    "\n",
    "# Optimize hyperparameters with Optuna\n",
    "study = optuna.create_study(storage=storage,\n",
    "                            direction='maximize',\n",
    "                           )\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_mcc_callback])\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc23de4-a5ac-47f8-b80b-e2f9caeb4f97",
   "metadata": {},
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd637e7f-db1a-4a8c-9f7a-edb519f9bb11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 3000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\"]),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        \"od_type\": trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "        \"od_wait\": trial.suggest_int(\"od_wait\", 10, 50),\n",
    "        \"verbose\": False,\n",
    "        \"allow_writing_files\": False,\n",
    "        \"task_type\": 'GPU',\n",
    "        \"cat_features\": cat_feats\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],  # Validation set\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False                 # Suppress output\n",
    "    )\n",
    "    y_pred = model.predict(X_test)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    trial.set_user_attr(\"mcc\", mcc)\n",
    "    return mcc\n",
    "\n",
    "\n",
    "study_name = \"cat\"\n",
    "storage = \"sqlite:///cat.db\"\n",
    "\n",
    "study = optuna.create_study(storage=storage,\n",
    "                            study_name=study_name,\n",
    "                            direction=\"maximize\",\n",
    "                            sampler=TPESampler(n_startup_trials=20, multivariate=True),\n",
    "                            load_if_exists=True)\n",
    "\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_mcc_callback])\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24621f8-4734-4f48-8056-7dd6720690df",
   "metadata": {},
   "source": [
    "## LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7dfb03-3184-4c6b-9576-e1f507fdee35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"device\": 'cpu',\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params, early_stopping_rounds=20)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],  # Validation set\n",
    "        # verbose=False                 # Suppress output\n",
    "    )\n",
    "    y_pred = model.predict(X_test)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    trial.set_user_attr(\"mcc\", mcc)\n",
    "    return mcc\n",
    "\n",
    "\n",
    "study_name = \"lgb\"\n",
    "storage = \"sqlite:///lgb.db\"\n",
    "\n",
    "study = optuna.create_study(storage=storage,\n",
    "                            study_name=study_name,\n",
    "                            direction=\"maximize\",\n",
    "                            sampler=TPESampler(n_startup_trials=20, multivariate=True),\n",
    "                            load_if_exists=True)\n",
    "\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_mcc_callback])\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ad4ab",
   "metadata": {
    "papermill": {
     "duration": 0.038116,
     "end_time": "2024-08-16T07:29:19.595308",
     "exception": false,
     "start_time": "2024-08-16T07:29:19.557192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters={'n_estimators': 297, 'max_depth': 16, 'learning_rate': 0.03906159386409017, 'subsample': 0.6935900010487451, 'colsample_bytree': 0.5171160704967471, 'gamma': 0.00013710778966124443, 'lambda': 0.0017203271581656767, 'alpha': 8.501510750413265e-06, 'scale_pos_weight': 1.0017942891559255,'enable_categorical': True,'tree_method': 'hist', 'device': 'cuda'}\n",
    "\n",
    "# 0.984876834594928\n",
    "xgb_parameters={'n_estimators': 629, 'max_depth': 16, 'learning_rate': 0.10540811331505591, 'subsample': 0.9980081491289166, 'colsample_bytree': 0.7065318052513923, 'gamma': 2.8307622020907574e-06, 'lambda': 0.02456026309353021, 'alpha': 1.5584362263554227e-07, 'scale_pos_weight': 1.105994872793953, 'eta': 0.0010400771543147627, 'min_child_weight': 79, 'grow_policy': 'depthwise', 'max_leaves': 61,\n",
    "               'device': 'cuda'\n",
    "               }\n",
    "# 0.98473160011893\n",
    "cat_parameters={'iterations': 1472, 'learning_rate': 0.08436268683474936, 'depth': 8, 'l2_leaf_reg': 0.2621416701020154, 'bootstrap_type': 'Bayesian', 'random_strength': 4.490114031912514e-07, 'bagging_temperature': 0.42447506181344297, 'od_type': 'Iter', 'od_wait': 21,\n",
    "                \"task_type\": 'GPU',\n",
    "                \"cat_features\": cat_feats}\n",
    "# 0.9848032057376603\n",
    "lgb_parameters={'lambda_l1': 1.3323938321586053e-07, 'lambda_l2': 0.07774032281247541, 'num_leaves': 248, 'feature_fraction': 0.41087472855265783, 'bagging_fraction': 0.9928696340850532, 'bagging_freq': 4, 'min_child_samples': 97} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d97817-b606-4602-b615-05c08a5aebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(model, X, y, n_splits=5, random_state=4885):\n",
    "    skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    oof_probs, oof_mccs = [], []\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training {model.__class__.__name__}\")\n",
    "    print(\"=\"*80, end=\"\\n\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "        X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx, :], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mcc = matthews_corrcoef(y_pred, y_test)\n",
    "        oof_mccs.append(mcc)\n",
    "        oof_probs.append(model.predict_proba(test_data))\n",
    "        print(f\"--- Fold {fold+1} MCC Score: {mcc:.6f}\")\n",
    "    print(f\"\\n---> Mean MCC Score: {np.mean(oof_mccs):.6f} \\xb1 {np.std(oof_mccs):.6f}\\n\\n\")\n",
    "    return oof_probs, oof_mccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdb1cc-f1c5-4e68-8e51-3d9dad90d77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_probs = {}\n",
    "oof_probs['xgb'], _ = model_trainer(XGBClassifier(**xgb_parameters, enable_categorical=True), X, y, random_state=4885)\n",
    "oof_probs['cat'], _ = model_trainer(CatBoostClassifier(**cat_parameters), X, y, random_state=4885)\n",
    "oof_probs['lgb'], _ = model_trainer(LGBMClassifier(**lgb_parameters), X, y, random_state=4885)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5b5e9-1133-44f1-8646-3d464f2faee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_probs = np.mean(oof_probs['xgb'], axis=0)[:, 1]\n",
    "cat_probs = np.mean(oof_probs['cat'], axis=0)[:, 1]\n",
    "lgb_probs = np.mean(oof_probs['lgb'], axis=0)[:, 1]\n",
    "average_probs = np.mean([xgb_probs, cat_probs, lgb_probs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66906b62-7ebc-485c-be30-b4591f975fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _0.98508\n",
    "# Average the probabilities for class 1 from the three models\n",
    "average_probs = np.mean([xgb_probs, cat_probs, lgb_probs], axis=0)\n",
    "\n",
    "# Assuming you have the 'id' column from the test data\n",
    "id_column = sample_submission_data.pop('id')\n",
    "\n",
    "# Create a DataFrame for the submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'class': average_probs\n",
    "})\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('./kaggle/submission_xgb_cat_lgbm_0830_0.98508_prob.csv', index=False)\n",
    "print(\"Submission file created: submission_autog_ensemble_avg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc8d0b-6cfc-4088-ae5c-8ed3f8247c12",
   "metadata": {},
   "source": [
    "# 예측값으로 저장하는법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f4b62-b77f-4e17-9f9a-e75cf000c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = {}\n",
    "for model in oof_probs.keys():\n",
    "    oof_preds[model] = np.argmax(np.mean(oof_probs[model], axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9da044-09f1-4985-ad66-215e80b54116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./kaggle/playground-series-s4e8/sample_submission.csv\")\n",
    "preds = oof_preds['lgb']\n",
    "sub['class'] = label_encoder.inverse_transform(preds)\n",
    "sub.to_csv('./kaggle/playground-series-s4e8/submission_lgb_0830_111.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83606284-800d-444a-ab96-cca8687b08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(\"./kaggle/playground-series-s4e8/sample_submission.csv\")\n",
    "# preds = [pred for model, pred in oof_preds.items()]\n",
    "# md = mode(preds, axis=0)[0] if len(preds)>1 else preds[0]\n",
    "# sub['class'] = label_encoder.inverse_transform(md)\n",
    "# sub.to_csv('./kaggle/playground-series-s4e8/submission_xgb_cat_lgbm_0830_111.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 344.562172,
   "end_time": "2024-08-16T07:30:17.540225",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-16T07:24:32.978053",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
