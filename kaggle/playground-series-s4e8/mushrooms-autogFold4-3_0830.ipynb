{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd70bf5",
   "metadata": {
    "papermill": {
     "duration": 0.01075,
     "end_time": "2024-08-16T07:24:35.983041",
     "exception": false,
     "start_time": "2024-08-16T07:24:35.972291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#d8ecff; color: #009dff;margin:0; display:inline-block;padding:.4rem;border-radius:.25rem;border:1px solid #009dff\">Importing Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eee77a2",
   "metadata": {
    "papermill": {
     "duration": 2.705462,
     "end_time": "2024-08-16T07:24:38.698336",
     "exception": false,
     "start_time": "2024-08-16T07:24:35.992874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np, os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OrdinalEncoder\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, StratifiedShuffleSplit,\n",
    "    StratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report, confusion_matrix, accuracy_score,matthews_corrcoef\n",
    "import scipy\n",
    "import warnings\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from autogluon.core.metrics import make_scorer\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "warnings.filterwarnings('ignore')\n",
    "# Custom metric function\n",
    "def custom_mcc_metric(y_true, y_pred):\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    return mcc\n",
    "custom_mcc_scorer = make_scorer(name='mcc',\n",
    "                                score_func=custom_mcc_metric,\n",
    "                                greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ef89b",
   "metadata": {
    "papermill": {
     "duration": 0.009945,
     "end_time": "2024-08-16T07:24:38.718437",
     "exception": false,
     "start_time": "2024-08-16T07:24:38.708492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "  ### <p style=\"background-color: #fdefff;color:#c12eff;display: inline-block;padding:.6rem;border-radius:.5rem;border: 1px solid #c059ff\">Loading data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a10a225-88a2-4b75-9840-5df12c5eb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b00cf1",
   "metadata": {
    "papermill": {
     "duration": 15.322649,
     "end_time": "2024-08-16T07:24:54.050532",
     "exception": false,
     "start_time": "2024-08-16T07:24:38.727883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data : (3116945, 22)\n",
      "test_data : (2077964, 21)\n",
      "sample_submission_data : (2077964, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd(), \"kaggle/playground-series-s4e8/train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd(), \"kaggle/playground-series-s4e8/test.csv\"))\n",
    "sample_submission_data = pd.read_csv(os.path.join(os.getcwd(), \"kaggle/playground-series-s4e8/sample_submission.csv\"))\n",
    "\n",
    "print(\"train_data :\", train_data.shape)\n",
    "print(\"test_data :\", test_data.shape)\n",
    "print(\"sample_submission_data :\", sample_submission_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa22a9",
   "metadata": {
    "papermill": {
     "duration": 0.032892,
     "end_time": "2024-08-16T07:27:09.193886",
     "exception": false,
     "start_time": "2024-08-16T07:27:09.160994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#d8ecff; color: #009dff;margin:0; display:inline-block;padding:.4rem;border-radius:.25rem;border:1px solid #009dff\">Handling NaN Values And Less Frequent Categories</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235db843-e8d3-44f3-9f01-637c93a21c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['id', 'class', 'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color',\n",
    "#        'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
    "#        'stem-height', 'stem-width', 'stem-root', 'stem-surface', 'stem-color',\n",
    "#        'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color',\n",
    "#        'habitat', 'season', 'veil-info'],\n",
    "#       dtype='object')\n",
    "\n",
    "# 결측치와 특성 존재 여부를 동시에 다룰 수 있음: 앞에서 0과 1로 veil-type의 존재 여부를 표현하고, 뒤에서 'unknown'을 통해 veil-color의 결측치를 처리함으로써 두 정보를 효과적으로 결합할 수 있습니다.\n",
    "# 모델 학습에 유용한 정보 제공: 결측치나 특성의 존재 여부를 단순히 무시하지 않고, 이들을 결합하여 모델이 더 많은 패턴을 학습할 수 있게 도와줍니다.\n",
    "# Index(['w', 'y', 'n', 'u', 'k', 'e', 'g', 'p', 'r', 'o', 's', 'a', 't', 'd',\n",
    "#        'i', 'h', 'c', 'f', 'l', 'b', 'z', '8.25', '2.49', '3.32'],\n",
    "#       dtype='object', name='veil-color')\n",
    "# Index(['u', 'w', 'a', 'f', 'e', 'b', 'c', 'y', 'k', 'g', 'n', 's', 'r', 'd',\n",
    "#        'p', 'h', 'i', 'l', 'is None', 't', '21.11', '5.94'],\n",
    "#       dtype='object', name='veil-type')\n",
    "\n",
    "# Index(['f10', 'tnone', 't1', 't7', 't10', 't4', 't2', 't5', 't3', 't9',\n",
    "#        'fnone', 'f1', 'f2', 'f7', 'f4', 't8', 'f5', 'r2', 't6', 'f3', 'l4',\n",
    "#        't0', 'p5', 'z7', 'c10', 'x10', 'f9', 'f6', 's10', 'm9', 'hnone', 's1',\n",
    "#        'g3', 'g5', 'h7', 'e1', 'f0', 'r4', 'dnone', 's5', 'cnone', 'h1', 'p1',\n",
    "#        'h5', 'h10', 'w3', 'y2', 'a10', 'ynone', 'e10', 'p7', '10.310', 's2',\n",
    "#        'o2', 'g10', 'h2', 'g1', 's3', 'p3', 'knone', 'inone', 'nnone', 'rnone',\n",
    "#        'l5', 'c1', 'n10', 'c3', 'o10', 'e4', 'd10', 'f has-ring10', 'lnone',\n",
    "#        'c7', 'e3', 'y1', 'k10'],\n",
    "#       dtype='object', name='has-ring-type')\n",
    "\n",
    "train_data['veil-info'] = train_data['veil-type'].notna().astype(int).astype(str) + train_data['veil-color'].fillna('unknown')\n",
    "cap_shape_mapping = {'b': 0, 'c': 1, 'x': 2, 'f': 3, 's': 4, 'p': 5, 'o': 6}\n",
    "cap_color_mapping = {'n': 0, 'b': 1, 'g': 2, 'r': 3, 'p': 4, 'u': 5, 'e': 6, 'w': 7, 'y': 8, 'l': 9, 'o': 10, 'k': 11}\n",
    "ring_type_mapping = {'c': 0, 'e': 1, 'r': 2, 'g': 3, 'l': 4, 'p': 5, 's': 6, 'z': 7, 'y': 8, 'm': 9, 'f': 10}\n",
    "train_data['cap-shape'] = train_data['cap-shape'].map(cap_shape_mapping)\n",
    "train_data['cap-color'] = train_data['cap-color'].map(cap_color_mapping)\n",
    "train_data['has-ring-type'] = (\n",
    "    train_data['has-ring'] + \n",
    "    train_data['ring-type'].fillna('none').map(ring_type_mapping).apply(lambda x: f\"{x:.0f}\" if pd.notna(x) else 'none').str.replace('.0', '', regex=False)\n",
    ")\n",
    "\n",
    "test_data['veil-info'] = test_data['veil-type'].notna().astype(int).astype(str) + test_data['veil-color'].fillna('unknown')\n",
    "test_data['cap-shape'] = test_data['cap-shape'].map(cap_shape_mapping)\n",
    "test_data['cap-color'] = test_data['cap-color'].map(cap_color_mapping)\n",
    "test_data['has-ring-type'] = (\n",
    "    test_data['has-ring'] + \n",
    "    test_data['ring-type'].fillna('none').map(ring_type_mapping).apply(lambda x: f\"{x:.0f}\" if pd.notna(x) else 'none').str.replace('.0', '', regex=False)\n",
    ")\n",
    "train_data = train_data.drop(['id', 'veil-color', 'veil-type', 'has-ring', 'ring-type'], axis=1)\n",
    "test_data = test_data.drop(['id', 'veil-color', 'veil-type', 'has-ring', 'ring-type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ca3de9",
   "metadata": {
    "papermill": {
     "duration": 12.420604,
     "end_time": "2024-08-16T07:27:41.801476",
     "exception": false,
     "start_time": "2024-08-16T07:27:29.380872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    threshold = 100\n",
    "    \n",
    "    cat_feats = ['cap-shape', 'cap-surface', 'cap-color',\n",
    "       'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
    "       'stem-root', 'stem-surface', 'stem-color', 'spore-print-color',\n",
    "       'habitat', 'season', 'veil-info', 'has-ring-type']\n",
    "    \n",
    "    for feat in cat_feats:\n",
    "        if df[feat].dtype.name == 'category':\n",
    "            # Add 'missing' and 'noise' to categories if not present\n",
    "            if 'missing' not in df[feat].cat.categories:\n",
    "                df[feat] = df[feat].cat.add_categories('missing')\n",
    "            if 'noise' not in df[feat].cat.categories:\n",
    "                df[feat] = df[feat].cat.add_categories('noise')\n",
    "        else:\n",
    "            # Convert to category and add new categories\n",
    "            df[feat] = df[feat].astype('category')\n",
    "            df[feat] = df[feat].cat.add_categories(['missing', 'noise'])\n",
    "        \n",
    "        # Fill missing values with 'missing'\n",
    "        df[feat] = df[feat].fillna('missing')\n",
    "        \n",
    "        # Replace infrequent categories with 'noise'\n",
    "        counts = df[feat].value_counts(dropna=False)\n",
    "        infrequent_categories = counts[counts < threshold].index\n",
    "        df[feat] = df[feat].apply(lambda x: 'missing' if x in infrequent_categories else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "train_data = cleaning(train_data)\n",
    "test_data = cleaning(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cfd7ec-7938-440d-ad5d-60d349e068cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_features = ['stem-width', 'stem-height']\n",
    "group_means_train = train_data.groupby(group_by_features)['cap-diameter'].mean()\n",
    "\n",
    "def fill_na_with_group_mean(row):\n",
    "    if pd.isna(row['cap-diameter']):\n",
    "        group = tuple(row[group_by_features])\n",
    "        return group_means_train.get(group, np.nan) \n",
    "    else:\n",
    "        return row['cap-diameter']\n",
    "\n",
    "train_data['cap-diameter'] = train_data.apply(fill_na_with_group_mean, axis=1)\n",
    "test_data['cap-diameter'] = test_data.apply(fill_na_with_group_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9310106f-92d0-4ee5-9508-91cdff972390",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_features = ['stem-width', 'stem-height']\n",
    "group_means_train = train_data.groupby(group_by_features)['cap-diameter'].mean()\n",
    "group_by_features = ['stem-width', 'stem-height']\n",
    "\n",
    "# Calculate group means for the train data\n",
    "group_means_train = train_data.groupby(group_by_features)['cap-diameter'].mean()\n",
    "\n",
    "def fill_na_with_group_mean(row, group_means):\n",
    "    if pd.isna(row['cap-diameter']):\n",
    "        group = tuple(row[group_by_features])\n",
    "        return group_means.get(group, np.nan)\n",
    "    else:\n",
    "        return row['cap-diameter']\n",
    "\n",
    "# Apply to train_data using train group means\n",
    "train_data['cap-diameter'] = train_data.apply(fill_na_with_group_mean, axis=1, group_means=group_means_train)\n",
    "\n",
    "# Apply the same group means from train_data to test_data\n",
    "test_data['cap-diameter'] = test_data.apply(fill_na_with_group_mean, axis=1, group_means=group_means_train)\n",
    "###\n",
    "###\n",
    "# Calculate the mode from the training data\n",
    "cap_diameter_mode = train_data['cap-diameter'].mode()[0]\n",
    "stem_height_mode = train_data['stem-height'].mode()[0]\n",
    "\n",
    "# Fill missing values in the training data using the mode calculated from the training data\n",
    "train_data['cap-diameter'] = train_data['cap-diameter'].fillna(cap_diameter_mode)\n",
    "train_data['stem-height'] = train_data['stem-height'].fillna(stem_height_mode)\n",
    "\n",
    "# Fill missing values in the test data using the mode calculated from the training data\n",
    "test_data['cap-diameter'] = test_data['cap-diameter'].fillna(cap_diameter_mode)\n",
    "test_data['stem-height'] = test_data['stem-height'].fillna(stem_height_mode)\n",
    "\n",
    "cat_feats = ['cap-shape', 'cap-surface', 'cap-color',\n",
    "       'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n",
    "       'stem-root', 'stem-surface', 'stem-color', 'spore-print-color',\n",
    "       'habitat', 'season', 'veil-info', 'has-ring-type']\n",
    "\n",
    "for feat in cat_feats:\n",
    "    train_data[feat] = train_data[feat].astype('category')\n",
    "for feat in cat_feats:\n",
    "    test_data[feat] = test_data[feat].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48739aae",
   "metadata": {
    "papermill": {
     "duration": 0.030299,
     "end_time": "2024-08-16T07:29:18.447641",
     "exception": false,
     "start_time": "2024-08-16T07:29:18.417342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <p style=\"background-color:#d8ecff; color: #009dff;margin:0; display:inline-block;padding:.4rem;border-radius:.25rem;border:1px solid #009dff\">Splitting Data</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df8bd9c-131a-48c9-b7e6-5d07379834d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a209d53-2c4f-4b34-86d7-0ea002afa898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #129-Ubuntu SMP Fri Aug 2 19:25:20 UTC 2024\n",
      "CPU Count:          32\n",
      "Memory Avail:       120.06 GB / 125.57 GB (95.6%)\n",
      "Disk Space Avail:   1244.90 GB / 1712.40 GB (72.7%)\n",
      "===================================================\n",
      "Presets specified: ['optimize_for_deployment']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2337709 samples, 245.47 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./kaggle/autogluon_models/\"\n",
      "Train Data Rows:    2337709\n",
      "Train Data Columns: 19\n",
      "Tuning Data Rows:    779236\n",
      "Tuning Data Columns: 19\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    123071.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 139.72 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 15 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  4 | ['cap-diameter', 'stem-height', 'stem-width', 'kfold']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 15 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  4 | ['cap-diameter', 'stem-height', 'stem-width', 'kfold']\n",
      "\t2.6s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.72 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Warning: use_bag_holdout=True, but bagged mode is not enabled. use_bag_holdout will be ignored.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5811\t = Validation score   (mcc)\n",
      "\t1.5s\t = Training   runtime\n",
      "\t4.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5811\t = Validation score   (mcc)\n",
      "\t1.54s\t = Training   runtime\n",
      "\t3.33s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0360637\tvalid_set's mcc: 0.984655\n",
      "[2000]\tvalid_set's binary_logloss: 0.0355967\tvalid_set's mcc: 0.984932\n",
      "[3000]\tvalid_set's binary_logloss: 0.0354907\tvalid_set's mcc: 0.985027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.985\t = Validation score   (mcc)\n",
      "\t610.12s\t = Training   runtime\n",
      "\t6.23s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364656\tvalid_set's mcc: 0.98437\n",
      "[2000]\tvalid_set's binary_logloss: 0.0361873\tvalid_set's mcc: 0.984667\n",
      "[3000]\tvalid_set's binary_logloss: 0.0362607\tvalid_set's mcc: 0.984701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t594.08s\t = Training   runtime\n",
      "\t4.44s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9844\t = Validation score   (mcc)\n",
      "\t158.66s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9844\t = Validation score   (mcc)\n",
      "\t166.08s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t496.98s\t = Training   runtime\n",
      "\t3.97s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t90.78s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t93.87s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t593.82s\t = Training   runtime\n",
      "\t2.43s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t309.35s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9843\t = Validation score   (mcc)\n",
      "\t401.12s\t = Training   runtime\n",
      "\t2.29s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0361726\tvalid_set's mcc: 0.984485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9845\t = Validation score   (mcc)\n",
      "\t223.05s\t = Training   runtime\n",
      "\t2.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.174, 'RandomForestEntr': 0.174, 'NeuralNetFastAI': 0.174, 'KNeighborsUnif': 0.087, 'LightGBM': 0.087, 'RandomForestGini': 0.087, 'XGBoost': 0.087, 'LightGBMLarge': 0.087, 'CatBoost': 0.043}\n",
      "\t0.9853\t = Validation score   (mcc)\n",
      "\t33.3s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3818.92s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 26450.9 rows/s (779236 batch size)\n",
      "Deleting model KNeighborsDist. All files under ./kaggle/autogluon_models/models/KNeighborsDist will be removed.\n",
      "Deleting model ExtraTreesGini. All files under ./kaggle/autogluon_models/models/ExtraTreesGini will be removed.\n",
      "Deleting model ExtraTreesEntr. All files under ./kaggle/autogluon_models/models/ExtraTreesEntr will be removed.\n",
      "Deleting model NeuralNetTorch. All files under ./kaggle/autogluon_models/models/NeuralNetTorch will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./kaggle/autogluon_models/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fcfb53cea90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"n_folds\" : 4,\n",
    "    \"fold\" : 3,\n",
    "    \"seed\" : 69,\n",
    "    \"drop_cols\" : [],\n",
    "    \"target\" : \"class\",\n",
    "    \"presets\" : \"optimize_for_deployment\",\n",
    "    \"binary_threshold\" : 0.5,\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG[\"seed\"])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(kf.split(train_data, train_data['class'])):\n",
    "      train_data.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "def prepare_datasets(df, fold, drop_columns=[]):\n",
    "    _df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    _df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    # drop \"id\" column\n",
    "    _df_train = _df_train.drop(columns=drop_columns)\n",
    "    _df_valid = _df_valid.drop(columns=drop_columns)\n",
    "    \n",
    "    train_data = TabularDataset(_df_train)\n",
    "    valid_data = TabularDataset(_df_valid)\n",
    "    return train_data, valid_data\n",
    "\n",
    "train_data, valid_data = prepare_datasets(\n",
    "    train_data, CONFIG[\"fold\"], drop_columns=CONFIG[\"drop_cols\"]\n",
    ")\n",
    "\n",
    "# Initialize TabularPredictor with the custom MCC metric\n",
    "predictor = TabularPredictor(\n",
    "    label='class',\n",
    "    problem_type='binary',\n",
    "    eval_metric=custom_mcc_scorer,\n",
    "    path='./kaggle/autogluon_models/',\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    tuning_data=valid_data,\n",
    "    save_space=True,\n",
    "    presets=CONFIG[\"presets\"],\n",
    "    use_bag_holdout=True,\n",
    "    ag_args_fit={'num_gpus': 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c44d47-7b45-497c-a5a4-d8add85b232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fcfb53cea90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(valid_data, extra_metrics=[custom_mcc_scorer], silent=True)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fac435a-8a1b-4c4d-93fe-cc47f1b6fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(test_data)\n",
    "test_data['kfold'] = CONFIG[\"fold\"]\n",
    "y_test_pred = predictor.predict_proba(test_data).iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de1dff2-c34f-469a-a505-5162e16dde30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission5.csv\n"
     ]
    }
   ],
   "source": [
    "id_column = sample_submission_data.pop('id')\n",
    "# y_test_pred = predictor.predict(test_data)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'class': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('./kaggle/submission_autog_0830_fold3.csv', index=False)\n",
    "print(\"Submission file created: submission5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a0259-75ad-456c-9faa-988e8539cfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 344.562172,
   "end_time": "2024-08-16T07:30:17.540225",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-16T07:24:32.978053",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
